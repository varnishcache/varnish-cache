varnishtest "H/2 received data frames with padding"

barrier b1 sock 2

server s1 {
	rxreq
	expect req.url == "/1"
	expect req.body == abcde
	txresp
	rxreq
	expect req.bodylen == 81500
	txresp
	rxreq
	txresp
	expect req.body == a
} -start

varnish v1 -cliok "param.set fetch_chunksize 64k"
varnish v1 -vcl+backend {
	import vtc;
	sub vcl_recv {
		if (req.url == "/3") {
			vtc.barrier_sync("${b1_sock}");
		}
	}
} -start

varnish v1 -cliok "param.set feature +http2"
varnish v1 -cliok "param.reset h2_initial_window_size"
varnish v1 -cliok "param.reset h2_rx_window_low_water"
varnish v1 -cliok "param.set debug +syncvsl"

client c1 {
	stream 1 {
		txreq -req POST -url /1 -hdr "content-length" "5" -nostrend
		txdata -data abcde -padlen 1
		rxresp
		expect resp.status == 200
	} -start
} -run

client c2 {
	# This makes use of the fact that Varnish will always send a
	# session window update immediately when receiving a data
	# frame. The four rxwinup before barrier sync on stream 0 matches
	# up with the four txdata frames sent early on the stream, and
	# makes sure that the session thread has exhausted its send window
	# completely before opening up and starting to consume rxbuf data
	# by unblocking the client thread stuck in vcl_recv. From that
	# point on window updates will also be sent on the stream.

	stream 3 {
		txreq -req POST -url /3 -hdr "content-length" "81500" -nostrend
		loop 3 {
			txdata -datalen 16300 -padlen 83 -nostrend
			rxwinup
			expect winup.size == 84
		}
		txdata -datalen 16300 -padlen 82 -nostrend
		rxwinup
		expect winup.size == 83
		barrier b1 sync
		rxwinup
		expect winup.size == 65200
		txdata -datalen 16300 -padlen 83
		rxresp
		expect resp.status == 200
	} -start
} -run

client c3 {
	stream 5 {
		txreq -req POST -url /5 -nostrend
		txdata -data a -padlen 255
		rxresp
		expect resp.status == 200
	} -start
} -run
